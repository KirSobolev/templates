{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from Benchmarking import RegressionBenchmark, ClassificationBenchmark\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-12 15:03:52,542 - INFO - Training LinearRegression...\n",
      "2025-02-12 15:03:52,550 - INFO - Training SVR...\n",
      "2025-02-12 15:03:52,604 - INFO - Training RandomForestRegressor...\n",
      "2025-02-12 15:03:52,841 - INFO - Training XGBRegressor...\n",
      "2025-02-12 15:03:52,981 - INFO - Training LGBMRegressor...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001184 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 228\n",
      "[LightGBM] [Info] Number of data points in the train set: 1034, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 1098.860203\n",
      "\n",
      "Benchmarking Results:\n",
      " |    | Model                 |      MSE |    RMSE |     MAE |     R2 |   Time (ms) |\n",
      "|---:|:----------------------|---------:|--------:|--------:|-------:|------------:|\n",
      "|  0 | LinearRegression      | 109563   | 331.002 | 253.364 | 0.7489 |        5.82 |\n",
      "|  1 | SVR                   | 433168   | 658.155 | 511.628 | 0.0072 |       33.68 |\n",
      "|  2 | RandomForestRegressor |  62660.1 | 250.32  | 173.956 | 0.8564 |      231.01 |\n",
      "|  3 | XGBRegressor          |  71446.7 | 267.295 | 175.405 | 0.8363 |      134.61 |\n",
      "|  4 | LGBMRegressor         |  71730.5 | 267.825 | 179.924 | 0.8356 |      387.13 |\n"
     ]
    }
   ],
   "source": [
    "df_reg =  read_csv(\"lin_reg_df_clean.csv\")\n",
    "df_reg_target = \"Price_euros\"\n",
    "reg = RegressionBenchmark(df_reg, df_reg_target)\n",
    "reg.benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-12 15:03:53,431 - INFO - Training LogisticRegression...\n",
      "/Users/kirillsobolev/Documents/GitHub/templates/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "2025-02-12 15:03:53,524 - INFO - Training SVC...\n",
      "2025-02-12 15:04:03,403 - INFO - Training RandomForestClassifier...\n",
      "2025-02-12 15:04:04,545 - INFO - Training XGBClassifier...\n",
      "2025-02-12 15:04:04,726 - INFO - Training LGBMClassifier...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 15498, number of negative: 8142\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 526\n",
      "[LightGBM] [Info] Number of data points in the train set: 23640, number of used features: 12\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655584 -> initscore=0.643675\n",
      "[LightGBM] [Info] Start training from score 0.643675\n",
      "\n",
      "Benchmarking Results:\n",
      " |    | Model                  |   Accuracy |   Precision |   Recall |   F1-score |   Time (ms) |\n",
      "|---:|:-----------------------|-----------:|------------:|---------:|-----------:|------------:|\n",
      "|  0 | LogisticRegression     |     0.7827 |      0.7699 |   0.7439 |     0.7528 |       85.73 |\n",
      "|  1 | SVC                    |     0.753  |      0.7657 |   0.6803 |     0.6906 |     7216.14 |\n",
      "|  2 | RandomForestClassifier |     0.8743 |      0.8683 |   0.8549 |     0.8608 |     1065.78 |\n",
      "|  3 | XGBClassifier          |     0.8745 |      0.8696 |   0.8536 |     0.8605 |      169.61 |\n",
      "|  4 | LGBMClassifier         |     0.8665 |      0.8621 |   0.8432 |     0.8511 |      437.32 |\n"
     ]
    }
   ],
   "source": [
    "df_class =  read_csv(\"log_reg_df_clean.csv\")\n",
    "df_class_target = \"booking_status\"\n",
    "classif = ClassificationBenchmark(df_class, df_class_target)\n",
    "classif.benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
